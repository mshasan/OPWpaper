{
    "collab_server" : "",
    "contents" : "library(snow)\nlibrary(qvalue)\nlibrary(tibble)\nlibrary(MASS)\n\n\ncl <- makeCluster(10, type = \"MPI\")\t\t# start zcluster 15 cores\n\n\nclusterExport(cl, \"qvalue\")\nclusterExport(cl, \"tibble\")\nclusterExport(cl, \"boxcox\")\n\n\n# define necessary functions (functions are taken from \"OPWeight\" library)\n# to avaiod installing \"OPWeight\" libray\n# to use parallel computing\n# ranksprob = p(rank=k|effect=ey)\n#===============================================================================\nprob_rank_givenEffect <- function(k, et, ey, nrep = 10000, m0, m1)\n{\n    t <- rnorm(nrep, et, 1)\n    p0 <- pnorm(-t)\n    p1 <- pnorm(ey - t)\n\n    mean0 <- (m0 - 1)*p0 + m1*p1 + 1\n    mean1 <- m0*p0 + (m1 - 1)*p1 + 1\n\n    var0 <- (m0 - 1)*p0*(1 - p0) + m1*p1*(1 - p1)\n    var1 <- m0*p0*(1 - p0) + (m1 - 1)*p1*(1 - p1)\n\n    prob <- ifelse(et == 0, mean(dnorm(k, mean0, sqrt(var0))),\n                   mean(dnorm(k, mean1, sqrt(var1))))\n    return(prob)\n}\n\n\nclusterExport(cl, \"prob_rank_givenEffect\")\n\n# find delta, the lagrange constant\n#---------------------------------------\nweight_by_delta <- function(delta, alpha = .05, et, m, m1, tail = 1L, ranksProb,\n                            effectType = c(\"continuous\", \"binary\"))\n{\n    if(effectType == \"continuous\"){\n        weight_per_delta <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(delta/(alpha*ranksProb)),\n                                                 lower.tail = FALSE)\n    } else {\n        weight_per_delta <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(delta*m/(alpha*m1*ranksProb)),\n                                                 lower.tail = FALSE)\n    }\n\n    sumWeight_per_delta <- sum(weight_per_delta, na.rm = TRUE)\n\n    return(sumWeight_per_delta)\n}\n\nclusterExport(cl, \"weight_by_delta\")\n\n# function to compute weight for continuous effect case\n#--------------------------------------------------------\nweight_continuous <- function(alpha, et, m, tail = 1L, delta, prob, weightSumVec)\n{\n    prob <- prob/sum(prob, na.rm = T)\n    deltaOut <- delta[min(abs(weightSumVec - m)) == abs(weightSumVec - m)]\n    deltaOut <- ifelse(length(deltaOut) > 1, .0001, deltaOut)\n    weight.out <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(deltaOut/(alpha*prob)),\n                                       lower.tail=FALSE)\n    sumWeight <- sum(weight.out, na.rm = TRUE)\n    normWeight <- if(sumWeight == 0) {rep(1, m)} else {weight.out/sumWeight*m}\n    return(normWeight)\n}\n\nclusterExport(cl, \"weight_continuous\")\n\n\n# main opw function-------------------\nopw <- function(pvalue, filter, prob_givenEffect = NULL, ranks = FALSE,\n                mean_filterEffect = NULL, mean_testEffect = NULL, weight = NULL,\n                effectType = c(\"continuous\", \"binary\"), alpha = .05, nrep = 10000,\n                tail = 1L, delInterval = .0001, method = c(\"BH\", \"BON\"), ... )\n{\n    # compute the number of tests------------\n    m = length(pvalue)\n    nullProp = qvalue(p = pvalue, pi0.method = \"bootstrap\")$pi0\n    m0 = ceiling(nullProp*m)\n    m1 = m - m0\n\n\n    # compute test statistics from the pvalues---------\n    if(tail == 1){\n        test <- qnorm(pvalue, lower.tail = FALSE)\n    } else {\n        test <- qnorm(pvalue/2, lower.tail = FALSE)\n    }\n\n    test[which(!is.finite(test))] <- NA\n\n    # estimate the true alterantive test effect sizes----------------\n    if(m1 == 0){\n        test_effect_vec <- 0\n    } else {\n        test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]\n    }\n\n    # estimate the mean test effect size-------------\n    if(!is.null(mean_testEffect)){\n        mean_testEffect <- mean_testEffect\n    } else {\n        if(effectType == \"continuous\"){\n            mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)\n        } else {\n            mean_testEffect <- median(test_effect_vec, na.rm = TRUE)\n        }\n    }\n\n    # estimate lambda from the box-cox transformation----------------\n    if(is.null(prob_givenEffect)){\n        # determine the side of the tests-------------\n        if(any(filter <= 0)){\n            stop(\"filter statistics need to be positive\")\n        }\n        bc <- boxcox(filter ~ test)\n        lambda <- bc$x[which.max(bc$y)]\n    }\n\n\n    # estimate the mean filter effect size------------------\n    if(!is.null(mean_filterEffect)){\n        mean_filterEffect <- mean_filterEffect\n    } else {\n        if(lambda == 0){\n            model <- lm(log(filter + .0001) ~ test)\n        } else {\n            model <- lm(filter**lambda ~ test)\n        }\n        mean_filterEffect <- model$coef[[1]] + model$coef[[2]]*mean_testEffect\n    }\n\n    # compute the probability of the filter given the mean filter effect\n    if(!is.null(prob_givenEffect)){\n        prob <- prob_givenEffect\n    } else {\n        message(\"computing probabilities\")\n        if(ranks == FALSE){\n            if(lambda == 0){\n                prob <- dnorm(log(filter + .0001), mean = 0, sd = 1)\n            } else {\n                prob <- dnorm(filter**lambda, mean = 0, sd = 1)\n            }\n        } else {\n            prob <- sapply(1:m, prob_rank_givenEffect, et = mean_filterEffect,\n                           ey = mean_filterEffect, nrep = nrep, m0 = m0, m1 = m1,\n                           monitor = monitor)\n        }\n        message(\"finished computing the probabilities\")\n    }\n\n\n    # compute the weights (always right-tailed)------------\n    if(!is.null(weight)){\n        wgt <- weight\n    } else {\n        message(\"computing weights\")\n        if(effectType == \"continuous\"){\n            wgt = weight_continuous(alpha = alpha, et = mean_testEffect, m = m,\n                                    tail = 1, delInterval = delInterval, prob = prob)\n        } else {\n            wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = m, m1 = m1,\n                                tail = 1, delInterval = delInterval, prob = prob)\n        }\n        message(\"finished computing the weights\")\n    }\n\n    # formulate a data set-------------\n    Data = tibble(pvalue, filter)\n    OD <- Data[order(Data$filter, decreasing=T), ]\n    Ordered.pvalue <- OD$pvalue\n\n    if(method == \"BH\"){\n        padj <- p.adjust(Ordered.pvalue/wgt, method = \"BH\")\n        rejections_list = OD[which((padj <= alpha) == TRUE), ]\n    } else {\n        rejections_list = OD[which((Ordered.pvalue <= alpha*wgt/m) == TRUE), ]\n    }\n\n    # outputs--------------\n    n_rejections = dim(rejections_list)[1]\n\n    return(list(totalTests = m, propNulls = nullProp,\n                probGivenEffect = prob, weight = wgt,\n                rejections = n_rejections, rejections_list = rejections_list))\n}\n\n\nclusterExport(cl, \"opw\")\n\n\n# start actual data analysis\n# suppose you have test pvalue and filter statistics from data\n\n\nTG_ONE_Eur_tbl <- read_delim(\"TG_ONE_Eur.tbl.sorted\",\"\\t\", escape_double = FALSE, trim_ws = TRUE)\n# head(TG_ONE_Eur_tbl)\n# names(TG_ONE_Eur_tbl)\n# dim(TG_ONE_Eur_tbl)\n# #View(TG_ONE_Eur_tbl)\nTG_ONE_Eur_tbl <- unique.data.frame(TG_ONE_Eur_tbl)\n\npgc_scz_full_2012_04 <- read.table(\"pgc.scz.full.2012-04.txt\", h=TRUE)\n# head(pgc_scz_full_2012_04)\n# names(pgc_scz_full_2012_04)\n# #View(pgc_scz_full_2012_04)\n# dim(pgc_scz_full_2012_04)\npgc_scz_full_2012_04 <- unique.data.frame(pgc_scz_full_2012_04)\n\n\n\ncommonSnp <- intersect(TG_ONE_Eur_tbl$MarkerName, pgc_scz_full_2012_04$snpid)\n# length(commonSnp)\n\nfilter_pvals <- TG_ONE_Eur_tbl$GC.Pvalue[pmatch(commonSnp, TG_ONE_Eur_tbl$MarkerName)]\nclusterExport(cl, \"filter_pvals\")\n\npvals <- pgc_scz_full_2012_04$pval[pmatch(commonSnp, pgc_scz_full_2012_04$snpid)]\nclusterExport(cl, \"pvals\")\n\nfilters <- qnorm(filter_pvals/2, lower.tail = FALSE)\nclusterExport(cl, \"filters\")\n\ntests <- qnorm(pval/2, lower.tail = FALSE)\nclusterExport(cl, \"tests\")\n\nfilters <- filters + .0001\nclusterExport(cl, \"filters\")\n\n# par(mfrow=c(2,2))\n# hist(pval)\n# hist(filter_pvals)\n# hist(tests)\n# hist(filters)\n\n# fite box-cox regression\n#--------------------------------\nbc <- boxcox(filters ~ tests)\nclusterExport(cl, \"bc\")\n\nlambda <- bc$x[which.max(bc$y)]\nclusterExport(cl, \"lambda\")\n\nmodel <- lm(filters**lambda ~ tests)\n# summary(model)\n# plot(model)\nclusterExport(cl, \"model\")\n\n\n# estimare m1 and m0-------\nnrep = 10000\nclusterExport(cl, \"nrep\")\n\nm = length(pvals)\nclusterExport(cl, \"m\")\n\nnullProp = qvalue(pvals, pi0.method=\"bootstrap\")$pi0\nclusterExport(cl, \"nullProp\")\n\nm0 = ceiling(nullProp*m)\nclusterExport(cl, \"m0\")\n\nm1 = m - m0\nclusterExport(cl, \"m1\")\n\n\n\n# estimate true alterantivetest effect sizes-----------\ntest_effect = sort(tests, decreasing = T)[1:m1]\nclusterExport(cl, \"test_effect\")\n\n\n\n# estimate mean effect sizes\net_cont = mean(test_effect, na.rm = T)\nclusterExport(cl, \"et_cont\")\n\ney_cont = model$coef[[1]] + model$coef[[2]]*et_cont\nclusterExport(cl, \"ey_cont\")\n\n\n\n# compute ranks probbaility (note that, et = ey, both should be the same)-------------\nprob_cont <-parSapply(cl, 1:m, prob_rank_givenEffect, et = ey_cont,\n                      ey = ey_cont, nrep = nrep, m0 = m0, m1 = m1)\n\nclusterExport(cl, \"prob_cont\")\n\n#------------------------------------------------------------\n# save the workspace to the file .RData in case\n# you can save the ranks probability for the future use, because it\n# does not depend on the whole data set one mena of the filter and test\n# Thus, it will not change in general\nsave.image(\"lipid_scz_data_analysis_prob.RData\")\n\n\n\nalpha <- .05\nclusterExport(cl, \"alpha\")\n\ndelta <- seq(0, 1, .0001)\nclusterExport(cl, \"delta\")\n\nweightSumVec <- parSapply(cl, delta, weight_by_delta, alpha = alpha, et = et_cont,\n                          m = m, m1 = m1, tail = 1, ranksProb = prob_cont,\n                          effectType = \"continuous\")\n\nclusterExport(cl, \"weightSumVec\")\n\n\nweight <- weight_continuous(alpha = alpha, et = et_cont, m = m, tail = 1L,\n                            delta = delta, prob = prob_cont, weightSumVec = weightSumVec)\nclusterExport(cl, \"weight\")\n\n\n# applying the main function-----------\nfinal_results <- opw(pvalue = pvals, filter=filters, prob_givenEffect = prob_cont,\n                     ranks = TRUE, weight = weight, effectType = \"continuous\",\n                     alpha = .05, method = \"BH\")\n\n\nstopCluster(cl)\n\n\n#------------------------------------------------------------\n# save the workspace to the file .RData in the cwd\nsave.image(\"lipid_scz_data_analysis.RData\")\n\n\n\n\n",
    "created" : 1495911823026.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "762643494",
    "id" : "A4DB1434",
    "lastKnownWriteTime" : 1495916199,
    "last_content_update" : 1495916194102,
    "path" : "U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-3/lipid_scz_data_analysis.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}