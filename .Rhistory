group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_Out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_Out <- ifelse(length(c_Out) > 1, -1, c_Out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
weight.out/sumWeight*m
}
}
return(norm_wgt)
}
cc = seq(-10, 10, .05)
et <- seq(0, 3, .5)
wgtSum_by_c <- sapply(cc, weightSum_by_c, m = 10000, effect_hat = et)
wgtSum_by_c
rm(list=ls())
weightSum_by_c <- function(c, m, gamma = .05,  alpha = .05, group = 5L,
tail = 1L, effect_hat)
{
groupSize <- m/group
weight_per_c <- tail*(m/alpha)*pnorm((effect_hat/2 + c/effect_hat),
lower.tail = FALSE)
wgt_smooth_c <- (1 - gamma)*weight_per_c + gamma*sum(weight_per_c)/group
wgt_per_test_c <- rep(wgt_smooth_c, each = groupSize)
sumWeight_per_c <- sum(wgt_per_test_c, na.rm = TRUE)
return(sumWeight_per_c)
}
roeder_wasserman_weight <- function(pvalue, gamma = .05, alpha = .05,
group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_Out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_Out <- ifelse(length(c_Out) > 1, -1, c_Out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
weight.out/sumWeight*m
}
}
return(norm_wgt)
}
m = 10000
set.seed(123)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue
# Compute wiehgt
weight = roeder_wasserman_weight(pvalue = pvals)
roeder_wasserman_weight <- function(pvalue, gamma = .05, alpha = .05,
group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_out <- ifelse(length(c_Out) > 1, -1, c_Out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
weight.out/sumWeight*m
}
}
return(norm_wgt)
}
weight = roeder_wasserman_weight(pvalue = pvals)
roeder_wasserman_weight <- function(pvalue, gamma = .05, alpha = .05,
group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_out <- ifelse(length(c_Out) > 1, -1, c_out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
weight.out/sumWeight*m
}
}
return(norm_wgt)
}
weight = roeder_wasserman_weight(pvalue = pvals)
roeder_wasserman_weight <- function(pvalue, gamma = .05, alpha = .05,
group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_out <- ifelse(length(c_out) > 1, -1, c_out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
weight.out/sumWeight*m
}
}
return(norm_wgt)
}
weight = roeder_wasserman_weight(pvalue = pvals)
# plot the weight
plot(weight)
roeder_wasserman_weight <- function(pvalue, gamma = .05, alpha = .05,
group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_out <- ifelse(length(c_out) > 1, -1, c_out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
wgt_smooth_cOut <- (1 - gamma)*weight.out + gamma*sum(weight.out)/group
wgt_per_test_cOut <- rep(wgt_smooth_cOut, each = groupSize)
sumWeight <- sum(wgt_per_test_cOut, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
wgt_per_test_cOut/sumWeight*m
}
}
return(norm_wgt)
}
weight = roeder_wasserman_weight(pvalue = pvals)
# plot the weight
plot(weight)
# compute number of rejections
Data <- tibble(tests, pvals, filters)
OD <- Data[order(Data$filters, decreasing = TRUE), ]
alpha = .05
rwd <- sum(OD$pvals <= alpha*weight/m)
bon <- sum(pvals <= alpha/m)
rwd
bon
rm(list=ls())
roeder_wasserman_weight <- function(pvalue, gamma = .05, alpha = .05,
group = 5L, tail = 1L, c_interval = .01)
{
m = length(pvalue)
# ordered pvalues, thus ordered tests------------
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
if(sum(effect_hat, na.rm = TRUE) == 0){
norm_wgt <- rep(1, m)
} else {
c <- seq(-10, 10, c_interval)
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
c_out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_out <- ifelse(length(c_out) > 1, -1, c_out)
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
wgt_smooth_cOut <- (1 - gamma)*weight.out + gamma*sum(weight.out)/group
wgt_per_test_cOut <- rep(wgt_smooth_cOut, each = groupSize)
sumWeight <- sum(wgt_per_test_cOut, na.rm = TRUE)
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
wgt_per_test_cOut/sumWeight*m
}
}
return(norm_wgt)
}
weightSum_by_c <- function(c, m, gamma = .05,  alpha = .05, group = 5L,
tail = 1L, effect_hat)
{
groupSize <- m/group
weight_per_c <- tail*(m/alpha)*pnorm((effect_hat/2 + c/effect_hat),
lower.tail = FALSE)
wgt_smooth_c <- (1 - gamma)*weight_per_c + gamma*sum(weight_per_c)/group
wgt_per_test_c <- rep(wgt_smooth_c, each = groupSize)
sumWeight_per_c <- sum(wgt_per_test_c, na.rm = TRUE)
return(sumWeight_per_c)
}
m = 10000
set.seed(123)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue
# Compute wiehgt
Data <- tibble(tests, pvals, filters)
OD <- Data[order(Data$filters, decreasing = TRUE), ]
weight = roeder_wasserman_weight(pvalue = OD$pvals)
# plot the weight
plot(weight)
# compute number of rejections
alpha = .05
rwd <- sum(OD$pvals <= alpha*weight/m)
bon <- sum(pvals <= alpha/m)
rwd
bon
pvalue = OD$pvals
gamma = .05
alpha = .05
group = 5L
tail = 1L
c_interval = .01
m = length(pvalue)
rankedtests <- qnorm(pvalue/tail, lower.tail = FALSE)
groupSize <- m/group
testGroup <- rep(1:group, each = groupSize)
testMeans <- as.vector(tapply(rankedtests, testGroup, mean))
testSd <- as.vector(tapply(rankedtests, testGroup, sd))
testSd
testMeans
pi_hat <- testMeans*testMeans/(testMeans*testMeans + testSd*testSd - 1)
effect_hat <- testMeans/pi_hat
effect_hat[pi_hat <= 1/groupSize] <- 0
pi_hat
effect_hat
sum(effect_hat, na.rm = TRUE) == 0
c <- seq(-10, 10, c_interval)
c
wgtSum_by_c <- sapply(c, weightSum_by_c, m, gamma = .05,  alpha = .05,
group = 5L, tail = 1L, effect_hat)
wgtSum_by_c
min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)
c_out <- c[min(abs(wgtSum_by_c - m)) == abs(wgtSum_by_c - m)]
c_out
c_out <- ifelse(length(c_out) > 1, -1, c_out)
c_out
weight.out <- tail*(m/alpha)*pnorm((effect_hat/2 + c_out/effect_hat),
lower.tail = FALSE)
weight.out
wgt_smooth_cOut <- (1 - gamma)*weight.out + gamma*sum(weight.out)/group
wgt_smooth_cOut
wgt_per_test_cOut <- rep(wgt_smooth_cOut, each = groupSize)
wgt_per_test_cOut
sumWeight <- sum(wgt_per_test_cOut, na.rm = TRUE)
sumWeight
norm_wgt <- if(sumWeight == 0) {
rep(1, m)
} else {
wgt_per_test_cOut/sumWeight*m
}
norm_wgt
sum(norm_wgt)
library(OPWpaper)
library(devtools)
install_github("mshasan/OPWeight")
install_github("mshasan/OPWeight", force = TRUE)
library(OPWpaper)
library(OPWpaper)
library(OPWpaper)
library(devtools)
install_github("mshasan/OPWeight")
install_github("mshasan/OPWpaper")
.libPaths()
build()
library(devtools)
use_travis()
use_travis()
for(in 1:2)
{
source("frank_data_analysis")
}
for(i in 1:2)
{
source("frank_data_analysis")
}
getwd()
setwd("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-Frank")
source("frank_data_analysis")
source("frank_data_analysis.R")
for(i in 1:2)
{
source("frank_data_analysis.R")
}
result <- c()
for(i in 1:2)
{
result[i] <- source("frank_data_analysis.R")
}
getwd()
result <- c()
for(i in 1:2)
{
result[i] <- source("frank_data_analysis.R")
}
result <- c()
for(i in 1:2)
{
result[i] <- source("frank_data_analysis.R")
}
source("frank_data_analysis.R")
datWeight_cont <- read.csv("weight_byEffect_cont_m10000.csv", h = TRUE)
setwd("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-1")
datWeight_cont <- read.csv("weight_byEffect_cont_m10000.csv", h = TRUE)
datWeightByNull = datWeight_cont[ , 11:20 ]
m = nrwo(datWeightByNull)
m = nrow(datWeightByNull)
m
apply(datWeightByNull, 2, sum)
apply(datWeightByNull, 2, sum)/apply(datWeightByNull, 2, sum)*m
colSum_wgt <- apply(datWeightByNull, 2, sum)
colSum_wgt
colSum_wgt == 0)
colSum_wgt == 0
weight_mat_pro <-
datWeightByNull[ , colSum_wgt == 0]
datWeightByNull[ , colSum_wgt == 0]
datWeightByNull
weight_mat_pro <-
datWeightByNull[ , colSum_wgt == 0] <- rep(1, m)
datWeightByNull[ , colSum_wgt == 0] <- rep(1, m)
datWeightByNull
datWeightByNull[,3:5] <- 0
datWeightByNull
colSum_wgt <- apply(datWeightByNull, 2, sum)
colSum_wgt
colSum_wgt == 0
weight_mat_pro <- datWeightByNull[ , colSum_wgt == 0] <- rep(1, m)
weight_mat_pro
datWeightByNull
datWeightByNull[,3:5] <- 0
datWeightByNull
m = nrow(datWeightByNull)
colSum_wgt <- apply(datWeightByNull, 2, sum)
datWeightByNull[ , colSum_wgt == 0] <- rep(1, m)
datWeightByNull
colSum_wgt2 <- apply(datWeightByNull, 2, sum)
colSum_wgt2
wgt_mat_norm <- colSum_wgt2/colSum_wgt2*m
wgt_mat_norm
wgt_mat_norm
datWeightByNull
m = nrow(datWeightByNull)
colSum_wgt <- colSums(datWeightByNull)
colSum_wgt
datWeightByNull = datWeight_cont[ , 11:20 ]
m = nrow(datWeightByNull)
colSum_wgt <- colSums(datWeightByNull)
colSum_wgt
datWeightByNull[ , colSum_wgt == 0] <- rep(1, m)
datWeightByNull
colSums(datWeightByNull)
wgt_mat_norm <- t(t(datWeightByNull)/colSums(datWeightByNull))*m
wgt_mat_norm
colSums(wgt_mat_norm)
runif_by_mean <- function(mean, n)
{
sd = mean/2
uni_rv <- mean + sd*scale(runif(n, 0, 1))
return(as.vector(uni_rv))
}
x = runif_by_mean(mean = 3, n = 100)
summary(x)
sapply(2, runif_by_mean, n = m)
ey_vec <- c(seq(0, 1, .2), 2, 3, 5, 8)
ey_vec
?rep
xf_mat <- sapply(ey_Vec, runif_by_mean, n = m)
xf_mat <- sapply(ey_vec, runif_by_mean, n = m)
xf_mat
is.matrix(xf_mat)
sapply(ey_Vec, rep, times = m)
sapply(ey_vec, rep, times = m)
effectType = "continuous"
if(effectType == "continuous"){
xf_mat <- sapply(ey_vec, runif_by_mean, n = m)
} else {
xf <- sapply(ey_vec, rep, times = m)
}
if(effectType == "continuous"){
xf_mat <- sapply(ey_vec, runif_by_mean, n = m)
} else {
xf_mat <- sapply(ey_vec, rep, times = m)
}
xf_mat
effectType = "binary"
if(effectType == "continuous"){
xf_mat <- sapply(ey_vec, runif_by_mean, n = m)
} else {
xf_mat <- sapply(ey_vec, rep, times = m)
}
xf_mat
?rnorm
rnorm(mean=1,sd=2, n=10)
cv=0
cv=1
rnorm(1, ey_vec, cv*ey_vec)
ey_vec
cv*ey_vec
rnorm(1, ey_vec, cv*ey_vec)
rnorm(10, ey_vec, cv*ey_vec)
rnorm(1,1,1)
rnorm(2,1,1)
se.seed(1)
set.seed(1)
rnorm(1,1,1)
set.seed(1)
rnorm(2,1,1)
rnorm(2,2,2)
set.seed(1)
rnorm(2,2,2)
set.seed(1)
rnorm(2,c(1,2),c(1,2))
set.seed(1)
rnorm(3,c(1,2,3),c(1,2,3))
length(ey_vec)
ey
ey=0
function(ey) rnorm(m, ey, cv*ey)
rnorm(m, ey, cv*ey)
xt_mat <- sapply(ey_vec, function(ey) rnorm(m, ey, cv*ey))
xt_mat
